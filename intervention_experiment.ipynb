{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Demonstration of intervention experiments with `ComputationGraph`\n",
    "\n",
    "## Setup\n",
    "\n",
    "Python modules for constructing a `ComputationGraph` and doing intervention experiments are in Atticus' Github repo `https://github.com/atticusg/Interchange`. To include the intervention modules here, you can make a local install of the `intervension` package:\n",
    "\n",
    "```\n",
    "$ cd path/to/Interchange\n",
    "$ pip install -e .\n",
    "```\n",
    "\n",
    "## A simple feed-forward network for determining equality\n",
    "\n",
    "In `torch_equality.py` I wrote a `TorchEqualityModel` that is basically a pytorch replication of the `MLPClassifier` model in `equality_experiment.py` which is implemented in scikit-learn.\n",
    "\n",
    "The `TorchEqualityModel` wraps around `TorchEqualityModule` which is a subclass of `torch.nn.Module`. The former contains training and prediction functionalities, similar to its scikit-learn counterpart.\n",
    "\n",
    "I use `TorchEqualityModel` and `TorchEqualityModule` to demonstrate our intervention model.\n",
    "\n",
    "**because of some wierd typing issue with jupyter notebook, it is suggested that if you make any changes to code in the `intervention` module, use *restart and run all* in the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training the TorchEqualityModel\n",
    "\n",
    "from torch_equality import *\n",
    "\n",
    "embed_dim = 10\n",
    "max_epochs = 100\n",
    "hidden_dim = 100\n",
    "train_size = 2000\n",
    "test_size = 500\n",
    "alpha = 0.001\n",
    "lr = 0.01\n",
    "\n",
    "train_dataset = TorchEqualityDataset(embed_dim=embed_dim, n_pos=train_size//2, n_neg=train_size//2)\n",
    "test_dataset = TorchEqualityDataset(embed_dim=embed_dim, n_pos=test_size//2, n_neg=test_size//2)\n",
    "\n",
    "train_dataset.test_disjoint(test_dataset)\n",
    "model = TorchEqualityModel(max_epochs=max_epochs,\n",
    "                           input_size=embed_dim*2,\n",
    "                           batch_size=1000,\n",
    "                           hidden_layer_size=hidden_dim,\n",
    "                           alpha=alpha,\n",
    "                           lr=lr,\n",
    "                           gpu=True)\n",
    "\n",
    "model.fit(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicitly defining a computation graph\n",
    "\n",
    "A computation graph can be defined manually, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from intervention import ComputationGraph, GraphNode\n",
    "\n",
    "# class TorchEqualityCompGraph(ComputationGraph):\n",
    "#     def __init__(self, model):\n",
    "#         assert isinstance(model, TorchEqualityModel)\n",
    "#         self.model = model\n",
    "#         self.module = model.module\n",
    "\n",
    "#         @GraphNode()\n",
    "#         def linear(x):\n",
    "#             # preprocess inputs here\n",
    "#             x = x.float().to(self.model.device)\n",
    "#             return self.module.linear(x)\n",
    "\n",
    "#         @GraphNode(linear)\n",
    "#         def activation(x):\n",
    "#             return self.module.activation(x)\n",
    "\n",
    "#         @GraphNode(activation)\n",
    "#         def logits(x):\n",
    "#             return self.module.output(x)\n",
    "\n",
    "#         @GraphNode(logits)\n",
    "#         def root(x):\n",
    "#             scores = self.module.sigmoid(x)\n",
    "#             return [1 if z >= 0.5 else 0 for z in scores]\n",
    "\n",
    "#         super().__init__(root)\n",
    "        \n",
    "# g = TorchEqualityCompGraph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically constructing a computation graph\n",
    "\n",
    "It can also be automatically extracted given an instance of a `torch.nn.Module`, using the `CompGraphConstructor`.\n",
    "\n",
    "The computation graph is constructed dynamically, and an input instance is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2604, -0.1911,  0.2648,  0.4248, -0.0555, -0.3701,  0.0138, -0.3214,\n",
      "        -0.2608, -0.3415, -0.2604, -0.1911,  0.2648,  0.4248, -0.0555, -0.3701,\n",
      "         0.0138, -0.3214, -0.2608, -0.3415])\n",
      "current_input in make_graph None\n",
      "I am in module linear I have 1 inputs\n",
      "I am in module activation I have 1 inputs\n",
      "I am in module output I have 1 inputs\n",
      "I am in module sigmoid I have 1 inputs\n",
      "<class 'intervention.computation_graph.GraphInput'>\n"
     ]
    }
   ],
   "source": [
    "from intervention import CompGraphConstructor, GraphInput, Intervention\n",
    "\n",
    "module = model.module\n",
    "input_0 = torch.tensor(test_dataset.X[0])\n",
    "input_0 = input_0.float()\n",
    "\n",
    "print(input_0)\n",
    "g, input_0 = CompGraphConstructor.construct(module, input_0, device=model.device)\n",
    "print(type(input_0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervene on entire tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check type of inputs in compute <class 'intervention.computation_graph.GraphInput'>\n",
      "check type of inputs in compute <class 'intervention.computation_graph.GraphInput'>\n",
      "res_0: tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>) res_3: tensor([0.0117], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "--- intervene, type of interve_3_0 <class 'intervention.computation_graph.Intervention'>\n",
      "input_0 before intervention tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after intervention tensor([0.0117], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input_0 = GraphInput({\"linear\": torch.tensor(test_dataset.X[0]).float()}, device=model.device)\n",
    "input_3 = GraphInput({\"linear\": torch.tensor(test_dataset.X[3]).float()}, device=model.device)\n",
    "\n",
    "res_0 = g.compute(input_0)\n",
    "res_3 = g.compute(input_3)\n",
    "\n",
    "print(\"res_0:\", res_0, \"res_3:\", res_3)\n",
    "\n",
    "# Use input_0 as input, but set the result of \"activation\" node to that of input_3\n",
    "interv_3_0 = Intervention(base=input_0, intervention={\"activation\": g.get_result(\"activation\", input_3)})\n",
    "\n",
    "print(\"--- intervene, type of interve_3_0\", type(interv_3_0))\n",
    "before, after = g.intervene(interv_3_0)\n",
    "\n",
    "print(\"input_0 before intervention %s, after intervention %s\" % (before, after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervene on a part of a tensor\n",
    "\n",
    "We can specify which part of a tensor we would like to intervene by adding indexing after a node's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_0 before intervention tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after intervention tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "in2 = Intervention(input_0)\n",
    "\n",
    "replace_value = g.get_result(\"activation\", input_3)[:10]\n",
    "in2.intervention = {\"activation[:10]\": replace_value}\n",
    "\n",
    "before, after = g.intervene(in2)\n",
    "print(\"input_0 before intervention %s, after intervention %s\" % (before, after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to intervene on part of a tensor\n",
    "\n",
    "Sometimes we would like more flexibility when intervening on a part of a tensor, for instance if the intervention location in a tensor changes dynamically. \n",
    "\n",
    "The way to do this is to provide a `dict` to the `locs` parameter of the `Intervention()` constructor. The keys in the dict are `str`s for node names, and values being any of the following:\n",
    "\n",
    "1. `LOC[...]`. A way to specify the indexing in the exact same way you would index into a tensor, but not actually getting the values at a tensor location.\n",
    "2. Indexing in a string form\n",
    "3. an `int` for single elements in a tensor.\n",
    "4. a tuple with `int`s, `slice` objects, and/or `Ellipsis` objects.\n",
    "\n",
    "For example the following are equivalent:\n",
    "\n",
    "```\n",
    "intervention = {\"node_a[5]\": value_a,\n",
    "                \"node_b[:10,:,10:]\": value_b,\n",
    "                \"node_c[:5,...]\": value_c,\n",
    "                \"node_d[5:10]\": value_d}\n",
    "interv = Intervention(base=some_base, intervention=intervention)\n",
    "```\n",
    "and \n",
    "```\n",
    "intervention = {\"node_a\": value_a,\n",
    "                \"node_b\": value_b,\n",
    "                \"node_c\": value_c,\n",
    "                \"node_d\": value_d}\n",
    "locs = {\"node_a\": 5,\n",
    "        \"node_b\": LOC[:10,:,10:],\n",
    "        \"node_c\": \":5,...\",\n",
    "        \"node_d\": slice(5,10)}\n",
    "interv = Intervention(base=some_base, intervention=intervention, locs=locs)\n",
    "```\n",
    "\n",
    "Another example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(1, None, None), 2, 3, Ellipsis)\n",
      "Replace indices 0 to 20 with values from `act3`. Before tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "Replace indices 20 to 40 with values from `act3`. Before tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "Replace indices 40 to 60 with values from `act3`. Before tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "Replace indices 60 to 80 with values from `act3`. Before tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "Replace indices 80 to 100 with values from `act3`. Before tensor([0.9661], device='cuda:0', grad_fn=<SigmoidBackward>), after tensor([0.9330], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "from intervention import LOC\n",
    "\n",
    "print(LOC[1:, 2, 3, ...])\n",
    "\n",
    "act3 = g.get_result(\"activation\", input_3)\n",
    "step = 20\n",
    "for i in range(0, 100, step):\n",
    "    replace_value = act3[i:i+step]\n",
    "    intervention = {\"activation\": replace_value}\n",
    "    locs = {\"activation\": LOC[i:i+step]}\n",
    "    interv = Intervention(base=input_0, intervention=intervention, locs=locs)\n",
    "    \n",
    "    before, after = g.intervene(in2)\n",
    "    print(\"Replace indices %d to %d with values from `act3`. Before %s, after %s\" % (i, i+step, before, after))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
